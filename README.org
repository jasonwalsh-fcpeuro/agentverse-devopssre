#+TITLE: AgentVerse DevOps/SRE Infrastructure
#+AUTHOR: AgentVerse Team
#+DATE: 2025

[[https://img.shields.io/badge/GCP-Cloud%20Run-blue.svg]]
[[https://img.shields.io/badge/Container-Docker-2496ED.svg?logo=docker]]
[[https://img.shields.io/badge/Registry-Artifact%20Registry-4285F4.svg?logo=google-cloud]]
[[https://img.shields.io/badge/AI-Vertex%20AI-FF6F00.svg?logo=google-cloud]]
[[https://img.shields.io/badge/Model-Gemma-brightgreen.svg]]
[[https://img.shields.io/badge/Runtime-VLLM-orange.svg]]
[[https://img.shields.io/badge/Local-Ollama-black.svg]]
[[https://img.shields.io/badge/Status-Active-success.svg]]

* Overview

AgentVerse DevOps/SRE infrastructure for deploying and managing AI agents on Google Cloud Platform. This repository provides automated deployment pipelines, monitoring, and scaling for AI workloads using Cloud Run, Vertex AI, and local Ollama integration.

* Architecture Flow

#+begin_src
┌─────────────┐     ┌──────────────┐     ┌─────────────┐
│   Ollama    │────▶│  Agent Hub   │────▶│  Cloud Run  │
│   (Local)   │     │              │     │  Services   │
└─────────────┘     └──────────────┘     └─────────────┘
                            │
                            ▼
                    ┌──────────────┐
                    │   Artifact   │
                    │   Registry   │
                    └──────────────┘
                            │
                    ┌───────┴────────┐
                    ▼                ▼
             ┌──────────┐     ┌──────────┐
             │   VLLM   │     │  Gemma   │
             │  Service │     │  Models  │
             └──────────┘     └──────────┘
#+end_src

* Quick Start

** Prerequisites

- Google Cloud SDK installed and authenticated
- Docker installed and running
- Ollama (optional, for local development)
- Make utility
- Bash shell

** Setup

1. Clone the repository:
   #+begin_src bash
   git clone git@github.com:weimeilin79/agentverse-devopssre.git
   cd agentverse-devopssre
   #+end_src

2. Configure your GCP project:
   #+begin_src bash
   echo "your-project-id" > ~/project_id.txt
   #+end_src

3. Initialize environment:
   #+begin_src bash
   source set_env.sh
   #+end_src

4. Set up infrastructure:
   #+begin_src bash
   make setup
   #+end_src

* Environment Variables

| Variable | Description | Example |
|----------|-------------|---------|
| =PROJECT_ID= | GCP Project ID | =my-project-123= |
| =REGION= | GCP Region | =europe-west4= |
| =REPO_NAME= | Artifact Registry Repository | =agentverse-repo= |
| =OLLAMA_URL= | Ollama API Endpoint | =http://localhost:11434= |
| =VLLM_URL= | VLLM Service URL | =https://vllm-service.run.app= |
| =MODEL_ID= | Model Identifier | =google/gemma-3-1b-it= |

* Makefile Targets

#+begin_src bash
make help           # Show all available targets
make setup          # Complete setup (auth, repo, docker)
make validate       # Run all validation checks
make audit          # Perform security and config audit
make deploy         # Deploy services to Cloud Run
make clean          # Clean up resources
#+end_src

* System Validation

** Core Components Check

Run validation to ensure all components are properly configured:

#+begin_src bash
make validate
#+end_src

This checks:
- ✓ GCloud authentication
- ✓ Project configuration
- ✓ Artifact Registry setup
- ✓ Docker configuration
- ✓ Ollama connectivity
- ✓ Network configuration
- ✓ IAM permissions

** Security Audit

Perform a security audit:

#+begin_src bash
make audit
#+end_src

Validates:
- API enablement
- Service account permissions
- Network security rules
- Secret management
- Container vulnerabilities

* Services

** Ollama Integration

Local Ollama instance for development:
- Auto-detected when running
- Falls back to Cloud Run when unavailable
- Models: qwen2.5, mistral, llama3.2-vision

** VLLM Service

High-performance inference engine:
- Optimized for Gemma models
- GPU acceleration
- Batch processing support

** Cloud Run Services

Managed serverless containers:
- Auto-scaling
- HTTPS endpoints
- Regional deployment

* Monitoring & Observability

** Logs

View service logs:
#+begin_src bash
gcloud logging read "resource.type=cloud_run_revision" --limit 50
#+end_src

** Metrics

Monitor service metrics:
#+begin_src bash
gcloud monitoring metrics-descriptors list --filter="metric.type:run.googleapis.com"
#+end_src

* Troubleshooting

** Common Issues

*** Authentication Failed
#+begin_src bash
gcloud auth login
gcloud auth application-default login
#+end_src

*** Docker Permission Denied
#+begin_src bash
gcloud auth configure-docker ${REGION}-docker.pkg.dev
#+end_src

*** Ollama Not Detected
#+begin_src bash
ollama serve  # Start Ollama service
make validate # Re-run validation
#+end_src

*** Build Failures
#+begin_src bash
gcloud builds list --limit=5  # Check recent builds
make clean && make setup       # Clean and retry
#+end_src

* Development Workflow

** Local Development

1. Start Ollama:
   #+begin_src bash
   ollama serve
   #+end_src

2. Set environment:
   #+begin_src bash
   source set_env.sh
   #+end_src

3. Run local tests:
   #+begin_src bash
   make test-local
   #+end_src

** Deployment

1. Build and push images:
   #+begin_src bash
   make build
   #+end_src

2. Deploy to Cloud Run:
   #+begin_src bash
   make deploy
   #+end_src

3. Validate deployment:
   #+begin_src bash
   make validate-deploy
   #+end_src

* Repository Structure

#+begin_src
.
├── Makefile              # Build and deployment automation
├── README.org            # This file
├── set_env.sh           # Environment configuration
├── warmup.sh            # Cache warming script
├── init.sh              # Initial setup script
├── cloudbuild-*.yaml    # Cloud Build configurations
├── agents/              # Agent implementations
├── services/            # Service configurations
└── tests/               # Test suites
#+end_src

* Contributing

** Fork Workflow

1. Fork the repository
2. Create feature branch
3. Make changes
4. Run validation: =make validate=
5. Submit pull request

** Development Guidelines

- Follow GCP best practices
- Maintain security standards
- Document all changes
- Include tests
- Update Makefile targets

* Security Considerations

- Never commit credentials
- Use Secret Manager for sensitive data
- Enable VPC Service Controls
- Implement least privilege IAM
- Regular security audits

* License

[Specify your license here]

* Support

- Issues: [[https://github.com/weimeilin79/agentverse-devopssre/issues]]
- Fork: [[https://github.com/jasonwalsh-fcpeuro/agentverse-devopssre]]

* Links

- [[https://cloud.google.com/run][Google Cloud Run Documentation]]
- [[https://cloud.google.com/vertex-ai][Vertex AI Documentation]]
- [[https://ollama.ai][Ollama Documentation]]
- [[https://vllm.ai][VLLM Documentation]]