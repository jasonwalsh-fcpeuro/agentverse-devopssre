# Cloud Build configuration for Ollama with Gemma models on Cloud Run
# This builds and deploys a containerized Ollama service with pre-loaded models

substitutions:
  _REGION: europe-west4
  _REPO_NAME: agentverse-repo
  _SERVICE_NAME: gemma-ollama-baked-service
  _IMAGE_TAG: latest

options:
  machineType: 'E2_HIGHCPU_8'
  logging: CLOUD_LOGGING_ONLY

steps:
  # Step 1: Build the Docker image with pre-loaded models
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-ollama-image'
    args: 
      - 'build'
      - '-t'
      - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_REPO_NAME}/${_SERVICE_NAME}:${_IMAGE_TAG}'
      - '-t'
      - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_REPO_NAME}/${_SERVICE_NAME}:${SHORT_SHA}'
      - '--cache-from'
      - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_REPO_NAME}/${_SERVICE_NAME}:${_IMAGE_TAG}'
      - '.'
    dir: 'ollama'

  # Step 2: Push the image to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    id: 'push-ollama-image'
    args: 
      - 'push'
      - '--all-tags'
      - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_REPO_NAME}/${_SERVICE_NAME}'
    waitFor: ['build-ollama-image']

  # Step 3: Deploy to Cloud Run with GPU support
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'deploy-to-cloud-run'
    entrypoint: gcloud
    args:
      - 'run'
      - 'deploy'
      - '${_SERVICE_NAME}'
      - '--image=${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_REPO_NAME}/${_SERVICE_NAME}:${_IMAGE_TAG}'
      - '--region=${_REGION}'
      - '--platform=managed'
      # Resource allocation
      - '--cpu=4'
      - '--memory=16Gi'
      - '--gpu=1'
      - '--gpu-type=nvidia-l4'
      - '--no-gpu-zonal-redundancy'
      # Service configuration
      - '--port=11434'
      - '--timeout=3600'
      - '--concurrency=4'
      - '--max-instances=2'
      - '--min-instances=1'
      # Environment variables
      - '--set-env-vars=OLLAMA_HOST=0.0.0.0:11434'
      - '--set-env-vars=OLLAMA_NUM_PARALLEL=4'
      - '--set-env-vars=OLLAMA_KEEP_ALIVE=24h'
      - '--set-env-vars=OLLAMA_MAX_LOADED_MODELS=3'
      # Performance settings
      - '--no-cpu-throttling'
      - '--no-cpu-boost'
      # Labels
      - '--labels=project=agentverse'
      - '--labels=service=ollama'
      - '--labels=model=gemma'
      # Access control
      - '--allow-unauthenticated'
      # Service account (optional - uncomment if using custom SA)
      # - '--service-account=${_SERVICE_ACCOUNT}'
    waitFor: ['push-ollama-image']

  # Step 4: Verify deployment
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'verify-deployment'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Verifying deployment..."
        SERVICE_URL=$(gcloud run services describe ${_SERVICE_NAME} \
          --region=${_REGION} \
          --format='value(status.url)')
        echo "Service deployed at: $${SERVICE_URL}"
        
        # Wait for service to be ready
        for i in {1..10}; do
          if curl -s "$${SERVICE_URL}/api/tags" > /dev/null; then
            echo "âœ“ Service is responding"
            curl -s "$${SERVICE_URL}/api/tags" | head -20
            break
          else
            echo "Waiting for service to be ready... ($$i/10)"
            sleep 10
          fi
        done
    waitFor: ['deploy-to-cloud-run']

# Images to be pushed to Artifact Registry
images:
  - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_REPO_NAME}/${_SERVICE_NAME}:${_IMAGE_TAG}'
  - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_REPO_NAME}/${_SERVICE_NAME}:${SHORT_SHA}'

# Timeout for the entire build
timeout: 1800s